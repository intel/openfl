{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "liquid-jacket",
   "metadata": {},
   "source": [
    "# Federated PyTorch UNET Tutorial\n",
    "## Using low-level Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-sharing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install dependencies if not already installed\n",
    "!pip install torchvision\n",
    "!pip install scikit-image\n",
    "!pip install dill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-distinction",
   "metadata": {},
   "source": [
    "### Describe the model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "#from model import UNet, soft_dice_loss, soft_dice_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "UNet model definition\n",
    "\"\"\"\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=3, n_classes=1):\n",
    "        super().__init__()\n",
    "        self.inc = double_conv(n_channels, 64)\n",
    "        self.down1 = down(64, 128)\n",
    "        self.down2 = down(128, 256)\n",
    "        self.down3 = down(256, 512)\n",
    "        self.down4 = down(512, 1024)\n",
    "        self.up1 = up(1024, 512)\n",
    "        self.up2 = up(512, 256)\n",
    "        self.up3 = up(256, 128)\n",
    "        self.up4 = up(128, 64)\n",
    "        self.outc = nn.Conv2d(64, n_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "def soft_dice_loss(output, target):\n",
    "    num = target.size(0)\n",
    "    m1 = output.view(num, -1)\n",
    "    m2 = target.view(num, -1)\n",
    "    intersection = m1 * m2\n",
    "    score = 2.0 * (intersection.sum(1) + 1) / (m1.sum(1) + m2.sum(1) + 1)\n",
    "    score = 1 - score.sum() / num\n",
    "    return score\n",
    "\n",
    "\n",
    "def soft_dice_coef(output, target):\n",
    "    num = target.size(0)\n",
    "    m1 = output.view(num, -1)\n",
    "    m2 = target.view(num, -1)\n",
    "    intersection = m1 * m2\n",
    "    score = 2.0 * (intersection.sum(1) + 1) / (m1.sum(1) + m2.sum(1) + 1)\n",
    "    return score.sum()\n",
    "\n",
    "\n",
    "class double_conv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.in_ch = in_ch\n",
    "        self.out_ch = out_ch\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(down, self).__init__()\n",
    "        self.mpconv = nn.Sequential(\n",
    "            nn.MaxPool2d(2), double_conv(in_ch, out_ch))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mpconv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, bilinear=False):\n",
    "        super(up, self).__init__()\n",
    "        self.in_ch = in_ch\n",
    "        self.out_ch = out_ch\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(\n",
    "                scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(\n",
    "                in_ch, in_ch // 2, 2, stride=2\n",
    "            )\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, (diffX // 2, diffX - diffX //\n",
    "                        2, diffY // 2, diffY - diffY // 2))\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "model_unet = UNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_adam = optim.Adam(model_unet.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-metallic",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-remainder",
   "metadata": {},
   "source": [
    "We ask user to keep all the test data in `data/` folder under the workspace as it will not be sent to collaborators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from hashlib import sha384\n",
    "import PIL\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as tsf\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-input",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.makedirs('data', exist_ok=True)\n",
    "!wget -nc 'https://datasets.simula.no/hyper-kvasir/hyper-kvasir-segmented-images.zip' -O ./data/kvasir.zip\n",
    "ZIP_SHA384 = 'e30d18a772c6520476e55b610a4db457237f151e'\\\n",
    "    '19182849d54b49ae24699881c1e18e0961f77642be900450ef8b22e7'\n",
    "assert sha384(open('./data/kvasir.zip', 'rb').read(\n",
    "    os.path.getsize('./data/kvasir.zip'))).hexdigest() == ZIP_SHA384\n",
    "!unzip -n ./data/kvasir.zip -d ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/segmented-images/'\n",
    "import numpy as np\n",
    "\n",
    "def read_data(image_path, mask_path):\n",
    "    \"\"\"\n",
    "    Read image and mask from disk.\n",
    "    \"\"\"\n",
    "    img = io.imread(image_path)\n",
    "    assert(img.shape[2] == 3)\n",
    "    mask = io.imread(mask_path)\n",
    "    return (img, mask[:, :, 0].astype(np.uint8))\n",
    "\n",
    "\n",
    "class KvasirDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Kvasir dataset contains 1000 images for all collaborators.\n",
    "    Args:\n",
    "        data_path: path to dataset on disk\n",
    "        collaborator_count: total number of collaborators\n",
    "        collaborator_num: number of current collaborator\n",
    "        is_validation: validation option\n",
    "    \"\"\"\n",
    "\n",
    "#     def __init__(self, data_path, collaborator_count, collaborator_num, is_validation):\n",
    "    def __init__(self, images_path = './data/segmented-images/images/', \\\n",
    "                        masks_path = './data/segmented-images/masks/',\n",
    "                        validation_fraction=1/8, is_validation=False):\n",
    "\n",
    "        self.images_path = images_path\n",
    "        self.masks_path = masks_path\n",
    "        self.images_names = [img_name for img_name in sorted(os.listdir(\n",
    "            self.images_path)) if len(img_name) > 3 and img_name[-3:] == 'jpg']\n",
    "\n",
    "        assert(len(self.images_names) > 2), \"Too few images\"\n",
    "        \n",
    "        validation_size = max(1, int(len(self.images_names) * validation_fraction))\n",
    "        \n",
    "        if is_validation:\n",
    "            self.images_names = self.images_names[-validation_size :]\n",
    "        else:\n",
    "            self.images_names = self.images_names[: -validation_size]\n",
    "        \n",
    "        # Prepare transforms\n",
    "        self.img_trans = tsf.Compose([\n",
    "            tsf.ToPILImage(),\n",
    "            tsf.Resize((332, 332)),\n",
    "            tsf.ToTensor(),\n",
    "            tsf.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "        self.mask_trans = tsf.Compose([\n",
    "            tsf.ToPILImage(),\n",
    "            tsf.Resize((332, 332), interpolation=PIL.Image.NEAREST),\n",
    "            tsf.ToTensor()])\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        name = self.images_names[index]\n",
    "        img, mask = read_data(self.images_path + name, self.masks_path + name)\n",
    "        img = self.img_trans(img).numpy()\n",
    "        mask = self.mask_trans(mask).numpy()\n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-groove",
   "metadata": {},
   "source": [
    "### Define Federated Learning tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_defined_in_notebook():\n",
    "    print('I will cause problems')\n",
    "\n",
    "    \n",
    "    \n",
    "def train(unet_model, train_loader, optimizer, device, loss_fn=soft_dice_loss):\n",
    "    \n",
    "    function_defined_in_notebook()\n",
    "    \n",
    "    unet_model.train()\n",
    "    unet_model.to(device)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data, target = torch.tensor(data).to(device), torch.tensor(\n",
    "            target).to(device, dtype=torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        output = unet_model(data)\n",
    "        loss = loss_fn(output=output, target=target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        \n",
    "    return {'train_loss': np.mean(losses),}\n",
    "\n",
    "\n",
    "def validate(unet_model, val_loader, device):\n",
    "    unet_model.eval()\n",
    "    unet_model.to(device)\n",
    "\n",
    "    val_score = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            samples = target.shape[0]\n",
    "            total_samples += samples\n",
    "            data, target = torch.tensor(data).to(device), \\\n",
    "                torch.tensor(target).to(device, dtype=torch.int64)\n",
    "            output = unet_model(data)\n",
    "            val = soft_dice_coef(output, target)\n",
    "            val_score += val.sum().cpu().numpy()\n",
    "            \n",
    "    return {'dice_coef': val_score / total_samples,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-protest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "obvious-tyler",
   "metadata": {},
   "source": [
    "## Describing FL experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-passion",
   "metadata": {},
   "source": [
    "### Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
    "MI = ModelInterface(model=model_unet, optimizer=optimizer_adam, framework_plugin=framework_adapter)\n",
    "\n",
    "# Save the initial model state\n",
    "initial_model = deepcopy(model_unet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-public",
   "metadata": {},
   "source": [
    "### Register dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-texas",
   "metadata": {},
   "source": [
    "We extract User dataset class implementation.\n",
    "Is it convinient?\n",
    "What if the dataset is not a class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserDataset:\n",
    "    def __init__(self, path_to_local_data):\n",
    "        print(f'User Dataset initialized with {path_to_local_data}')\n",
    "        \n",
    "        \n",
    "class OpenflMixin:   \n",
    "    def _delayed_init(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "        \n",
    "class FedDataset(OpenflMixin):\n",
    "    def __init__(self, UserDataset):\n",
    "        self.user_dataset_class = UserDataset\n",
    "        print('We implement all abstract methods from mixin in this class')\n",
    "        \n",
    "    def _delayed_init(self, data_path):\n",
    "        print('This method is called on the collaborator node')\n",
    "        dataset_obj = self.user_dataset_class(data_path)\n",
    "        \n",
    "        \n",
    "fed_dataset = FedDataset(UserDataset)\n",
    "fed_dataset._delayed_init('data path on the collaborator node')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedDataset(DataInterface):\n",
    "    def __init__(self, UserDatasetClass, **kwargs):\n",
    "        self.UserDatasetClass = UserDatasetClass\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def _delayed_init(self, data_path='1,1'):\n",
    "        # With the next command the local dataset will be loaded on the collaborator node\n",
    "        # For this example we have the same dataset on the same path, and we will shard it\n",
    "        # So we use `data_path` information for this purpose.\n",
    "        self.rank, self.world_size = [int(part) for part in data_path.split(',')]\n",
    "        \n",
    "        validation_fraction=1/8\n",
    "        self.train_set = self.UserDatasetClass(validation_fraction=validation_fraction, is_validation=False)\n",
    "        self.valid_set = self.UserDatasetClass(validation_fraction=validation_fraction, is_validation=True)\n",
    "        \n",
    "        # Do the actual sharding\n",
    "        self._do_sharding( self.rank, self.world_size)\n",
    "        \n",
    "    def _do_sharding(self, rank, world_size):\n",
    "        # This method relies on the dataset's implementation\n",
    "        # i.e. coupled in a bad way\n",
    "        self.train_set.images_names = self.train_set.images_names[ rank-1 :: world_size ]\n",
    "#         self.valid_set.images_names = self.valid_set.images_names[ rank-1 :: world_size ]\n",
    "        \n",
    "\n",
    "    def get_train_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks with optimizer in contract\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            self.train_set, num_workers=8, batch_size=self.kwargs['train_bs'], shuffle=True\n",
    "            )\n",
    "\n",
    "    def get_valid_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks without optimizer in contract\n",
    "        \"\"\"\n",
    "        return DataLoader(self.valid_set, num_workers=8, batch_size=self.kwargs['valid_bs'])\n",
    "\n",
    "    def get_train_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.train_set)\n",
    "\n",
    "    def get_valid_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.valid_set)\n",
    "    \n",
    "fed_dataset = FedDataset(KvasirDataset, train_bs=8, valid_bs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-kansas",
   "metadata": {},
   "source": [
    "### Register tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "TI = TaskInterface()\n",
    "import torch\n",
    "\n",
    "import tqdm\n",
    "\n",
    "def function_defined_in_notebook(some_parameter):\n",
    "    print('I will cause problems')\n",
    "    print(f'Also I accept a parameter and it is {some_parameter}')\n",
    "\n",
    "# We do not actually need to register additional kwargs, Just serialize them\n",
    "@TI.add_kwargs(**{'some_parameter': 42})\n",
    "@TI.register_fl_task(model='unet_model', data_loader='train_loader', \\\n",
    "                     device='device', optimizer='optimizer')     \n",
    "def train(unet_model, train_loader, optimizer, device, loss_fn=soft_dice_loss, some_parameter=None):\n",
    "    if not torch.cuda.is_available():\n",
    "        device = 'cpu'\n",
    "    \n",
    "    function_defined_in_notebook(some_parameter)\n",
    "    \n",
    "    train_loader = tqdm.tqdm(train_loader, desc=\"train\")\n",
    "    \n",
    "    unet_model.train()\n",
    "    unet_model.to(device)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data, target = torch.tensor(data).to(device), torch.tensor(\n",
    "            target).to(device, dtype=torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        output = unet_model(data)\n",
    "        loss = loss_fn(output=output, target=target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        \n",
    "    return {'train_loss': np.mean(losses),}\n",
    "\n",
    "\n",
    "@TI.register_fl_task(model='unet_model', data_loader='val_loader', device='device')     \n",
    "def validate(unet_model, val_loader, device):\n",
    "    unet_model.eval()\n",
    "    unet_model.to(device)\n",
    "    \n",
    "    val_loader = tqdm.tqdm(val_loader, desc=\"validate\")\n",
    "\n",
    "    val_score = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            samples = target.shape[0]\n",
    "            total_samples += samples\n",
    "            data, target = torch.tensor(data).to(device), \\\n",
    "                torch.tensor(target).to(device, dtype=torch.int64)\n",
    "            output = unet_model(data)\n",
    "            val = soft_dice_coef(output, target)\n",
    "            val_score += val.sum().cpu().numpy()\n",
    "            \n",
    "    return {'dice_coef': val_score / total_samples,}\n",
    "\n",
    "\n",
    "# @TI.register_fl_task(model='unet_model', data_loader='val_loader', device='device')     \n",
    "# def test_task(np_array):\n",
    "#     linear = nn.Linear(10, 5)\n",
    "#     return linear(torch.tensor(np_array, dtype=torch.float))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-bride",
   "metadata": {},
   "source": [
    "## Time to start a federated learning experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-baltimore",

   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a federation\n",
    "from openfl.interface.interactive_api.federation import Federation\n",
    "\n",
    "# 1) Run with TLS disabled (trusted environment)\n",
    "# will determine fqdn by itself\n",

    "federation = Federation(central_node_fqdn='localhost', disable_tls=True)\n",

    "federation = Federation(central_node_fqdn='nnlicv448.inn.intel.com', disable_tls=True)\n",

    "# First number which is a collaborators rank is also passed as a cuda device identifier\n",
    "col_data_paths = {'one': '1,2',\n",
    "                'two': '2,2'}\n",
    "federation.register_collaborators(col_data_paths=col_data_paths)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "# 2) Run with aggregator-collaborator mTLS \n",
    "# If the user wants to enable mTLS their must provide CA root chain, and signed key pair to the federation interface\n",
    "cert_chain = 'cert/cert_chain.crt'\n",
    "agg_certificate = 'cert/agg_certificate.crt'\n",
    "agg_private_key = 'cert/agg_private.key'\n",
    "\n",
    "federation = Federation(central_node_fqdn='nnlicv448.inn.intel.com', disable_tls=True,\n",
    "                       cert_chain=cert_chain, agg_certificate=agg_certificate, agg_private_key=agg_private_key)\n",
    "col_data_paths = {'one': '1,1',}\n",
    "federation.register_collaborators(col_data_paths=col_data_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adad7744",
   "metadata": {},
   "source": [
    "#### Certification of an aggregator\n",
    "* fx workspace certify: creates cert folder and CA as well as cert_chain\n",
    "* fx aggregator generate-cert-request --fqdn `FQDN`: you can pass a specific aggregator FQDN if you want\n",
    "* fx aggregator certify --fqdn `FQDN` --silent: signes aggregators cert\n",
    "<br> After that just pass the paths to required certs to the Federation API\n",
    "\n",
    "#### Certification of a collaborator\n",
    "just follow the usual procedure: <br>\n",
    "fx collaborator generate-cert-request -d {DATA_PATH} -n {COL} \n",
    "\n",
    "fx collaborator certify --request-pkg {COL_DIRECTORY}/{FED_WORKSPACE}/col_{COL}_to_agg_cert_request.zip\n",
    "\n",
    "fx collaborator certify --import {FED_DIRECTORY}/agg_to_col_{COL}_signed_cert.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an experimnet in federation\n",
    "fl_experiment = FLExperiment(federation=federation,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "lightweight-causing",
   "metadata": {
    "scrolled": false
   },

   "outputs": [],

   "source": [
    "# If I use autoreload I got a pickling error\n",
    "\n",
    "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
    "fl_experiment.prepare_workspace_distribution(model_provider=MI, task_keeper=TI, data_loader=fed_dataset, rounds_to_train=7, \\\n",
    "                              opt_treatment='CONTINUE_GLOBAL')\n",
    "# This command starts the aggregator server\n",
    "fl_experiment.start_experiment(model_provider=MI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c30b301",
   "metadata": {},
   "source": [
    "## Now we validate the best model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55acff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = fl_experiment.get_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fb5718d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidyuk/.virtualenvs/kvasir-test/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
     ]
    }
   ],
   "source": [
    "fed_dataset._delayed_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2acb7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validate:   0%|          | 0/16 [00:00<?, ?it/s]/home/davidyuk/.virtualenvs/kvasir-test/lib/python3.7/site-packages/ipykernel_launcher.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/davidyuk/.virtualenvs/kvasir-test/lib/python3.7/site-packages/ipykernel_launcher.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "validate: 100%|██████████| 16/16 [00:38<00:00,  2.39s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dice_coef': 0.2016089882850647}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating initial model\n",
    "validate(initial_model, fed_dataset.get_valid_loader(), 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c12ca93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validate:   0%|          | 0/16 [00:00<?, ?it/s]/home/davidyuk/.virtualenvs/kvasir-test/lib/python3.7/site-packages/ipykernel_launcher.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/davidyuk/.virtualenvs/kvasir-test/lib/python3.7/site-packages/ipykernel_launcher.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "validate: 100%|██████████| 16/16 [00:37<00:00,  2.37s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dice_coef': 0.4961296663284302}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating trained model\n",
    "validate(best_model, fed_dataset.get_valid_loader(), 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6734f6",
   "metadata": {},
   "source": [
    "## We can tune model further!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3940e75e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "start_experiment() got an unexpected keyword argument 'task_keeper'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-46cfc9583e88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mMI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelInterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_adam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework_plugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframework_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m fl_experiment.start_experiment(model_provider=MI, task_keeper=TI, data_loader=fed_dataset, rounds_to_train=4, \\\n\u001b[0;32m----> 3\u001b[0;31m                               opt_treatment='CONTINUE_GLOBAL')\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: start_experiment() got an unexpected keyword argument 'task_keeper'"
     ]
    }
   ],
   "source": [
    "MI = ModelInterface(model=best_model, optimizer=optimizer_adam, framework_plugin=framework_adapter)\n",
    "fl_experiment.start_experiment(model_provider=MI, task_keeper=TI, data_loader=fed_dataset, rounds_to_train=4, \\\n",
    "                              opt_treatment='CONTINUE_GLOBAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd786d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = fl_experiment.get_best_model()\n",
    "# Validating trained model\n",
    "validate(best_model, fed_dataset.get_valid_loader(), 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af49bc78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54981e40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "server.aggregator.tensor_db.tensor_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e47bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4ef836",
   "metadata": {},
   "outputs": [],
   "source": [
    "server.aggregator.tensor_db.tensor_db['tags'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d60c7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "server.aggregator.best_tensor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-valentine",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fl_experiment.plan.config['tasks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "TI.task_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-electric",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "[1,2,3] + [4,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-hygiene",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03c0769",
   "metadata": {},
   "outputs": [],
   "source": [
    "makedirs('./ho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4532a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0da92a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
