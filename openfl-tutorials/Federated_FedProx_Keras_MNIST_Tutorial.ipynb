{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Keras MNIST Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Install Tensorflow and MNIST dataset if not installed\n",
    "!pip install tensorflow==2.3.1 ~/repos/openfl-fork\n",
    "\n",
    "#Alternatively you could use the intel-tensorflow build\n",
    "# !pip install intel-tensorflow==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import openfl.native as fx\n",
    "from openfl.federated import FederatedModel,FederatedDataSet\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_intel_tensorflow():\n",
    "    \"\"\"\n",
    "    Check if Intel version of TensorFlow is installed\n",
    "    \"\"\"\n",
    "    import tensorflow as tf\n",
    "\n",
    "    print(\"We are using Tensorflow version {}\".format(tf.__version__))\n",
    "\n",
    "    major_version = int(tf.__version__.split(\".\")[0])\n",
    "    if major_version >= 2:\n",
    "        from tensorflow.python import _pywrap_util_port\n",
    "        print(\"Intel-optimizations (DNNL) enabled:\",\n",
    "              _pywrap_util_port.IsMklEnabled())\n",
    "    else:\n",
    "        print(\"Intel-optimizations (DNNL) enabled:\")\n",
    "\n",
    "test_intel_tensorflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the required packages, the next step is setting up our openfl workspace. To do this, simply run the `fx.init()` command as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup default workspace, logging, etc.\n",
    "fx.init('keras_cnn_mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to define our dataset and model to perform federated learning on. The dataset should be composed of a numpy arrayWe start with a simple fully connected model that is trained on the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and process training, validation, and test images/labels\n",
    "\n",
    "# Set the ratio of validation imgs, can't be 0.0\n",
    "VALID_PERCENT = 0.3\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "split_on = int((1 - VALID_PERCENT) * len(X_train))\n",
    "\n",
    "train_images = X_train[0:split_on,:,:]\n",
    "train_labels = to_categorical(y_train)[0:split_on,:]\n",
    "\n",
    "valid_images = X_train[split_on:,:,:]\n",
    "valid_labels = to_categorical(y_train)[split_on:,:]\n",
    "\n",
    "test_images = X_test\n",
    "test_labels = to_categorical(y_test)\n",
    "\n",
    "def preprocess(images):\n",
    "    #Normalize\n",
    "    images = (images / 255) - 0.5\n",
    "    #Flatten\n",
    "    images = images.reshape((-1, 784))\n",
    "    return images\n",
    "\n",
    "# Preprocess the images.\n",
    "train_images = preprocess(train_images)\n",
    "valid_images = preprocess(valid_images)\n",
    "test_images = preprocess(test_images)\n",
    "\n",
    "feature_shape = train_images.shape[1]\n",
    "classes = 10\n",
    "\n",
    "class UnbalancedFederatedDataset(FederatedDataSet):\n",
    "    def split(self, num_collaborators, shuffle=True, equally=False):\n",
    "        train_idx = self.split_dirichlet(self.y_train, num_collaborators)\n",
    "        X_train = np.array([self.X_train[idx] for idx in train_idx])\n",
    "        y_train = np.array([self.y_train[idx] for idx in train_idx])\n",
    "        \n",
    "        valid_idx = self.split_dirichlet(self.y_valid, num_collaborators)\n",
    "        X_valid = np.array([self.X_valid[idx] for idx in valid_idx])\n",
    "        y_valid = np.array([self.y_valid[idx] for idx in valid_idx])\n",
    "        \n",
    "        return [\n",
    "            FederatedDataSet(\n",
    "                X_train[i],\n",
    "                y_train[i],\n",
    "                X_valid[i],\n",
    "                y_valid[i],\n",
    "                batch_size=self.batch_size,\n",
    "                num_classes=self.num_classes\n",
    "            ) for i in range(num_collaborators)\n",
    "        ]\n",
    "    \n",
    "    def split_dirichlet(self, labels, num_collaborators):\n",
    "        min_size = 0\n",
    "        alpha = 0.5\n",
    "        n = len(labels)\n",
    "        while min_size < 10:\n",
    "            idx_batch = [[] for _ in range(num_collaborators)]\n",
    "            # for each class in the dataset\n",
    "            for k in range(self.num_classes):\n",
    "                idx_k = np.where(np.argmax(labels, axis=1) == k)[0]\n",
    "                np.random.shuffle(idx_k)\n",
    "                proportions = np.random.dirichlet(np.repeat(alpha, num_collaborators))\n",
    "                ## Balance\n",
    "                proportions = np.array([p * (len(idx_j) < n / num_collaborators) for p, idx_j in zip(proportions, idx_batch)])\n",
    "                proportions = proportions / proportions.sum()\n",
    "                proportions = (np.cumsum(proportions) * len(idx_k)).astype(int)[:-1]\n",
    "                idx_batch = [idx_j + idx.tolist() for idx_j, idx in zip(idx_batch, np.split(idx_k,proportions))]\n",
    "                min_size = min([len(idx_j) for idx_j in idx_batch])\n",
    "        return idx_batch\n",
    "\n",
    "fl_data = UnbalancedFederatedDataset(train_images,train_labels,valid_images,valid_labels,batch_size=32,num_classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import standard_ops\n",
    "\n",
    "\n",
    "@keras.utils.register_keras_serializable()\n",
    "class FedProxOptimizer(keras.optimizers.Optimizer):\n",
    "    def __init__(self, learning_rate=0.01, mu=0.01, name='FedProxOptimizer', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "\n",
    "        self._set_hyper(\"learning_rate\", learning_rate)\n",
    "        self._set_hyper(\"mu\", mu)\n",
    "\n",
    "        self._lr_t = None\n",
    "        self._mu_t = None\n",
    "\n",
    "    def _prepare(self, var_list):\n",
    "        self._lr_t = tf.convert_to_tensor(self._get_hyper('learning_rate'), name=\"lr\")\n",
    "        self._mu_t = tf.convert_to_tensor(self._get_hyper('mu'), name=\"mu\")\n",
    "\n",
    "    def _create_slots(self, var_list):\n",
    "        for v in var_list:\n",
    "            self.add_slot(v, \"vstar\")\n",
    "\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        lr_t = tf.cast(self._lr_t, var.dtype.base_dtype)\n",
    "        mu_t = tf.cast(self._mu_t, var.dtype.base_dtype)\n",
    "        vstar = self.get_slot(var, \"vstar\")\n",
    "\n",
    "        var_update = var.assign_sub(lr_t * (grad + mu_t * (var - vstar)))\n",
    "\n",
    "        return tf.group(*[var_update, ])\n",
    "\n",
    "    def _apply_sparse_shared(self, grad, var, indices, scatter_add):\n",
    "        lr_t = tf.cast(self._lr_t, var.dtype.base_dtype)\n",
    "        mu_t = tf.cast(self._mu_t, var.dtype.base_dtype)\n",
    "        vstar = self.get_slot(var, \"vstar\")\n",
    "        v_diff = vstar.assign(mu_t * (var - vstar), use_locking=self._use_locking)\n",
    "\n",
    "        with tf.control_dependencies([v_diff]):\n",
    "            scaled_grad = scatter_add(vstar, indices, grad)\n",
    "        var_update = var.assign_sub(lr_t * scaled_grad)\n",
    "\n",
    "        return tf.group(*[var_update, ])\n",
    "\n",
    "    def _resource_apply_sparse(self, grad, var):\n",
    "        return self._apply_sparse_shared(\n",
    "            grad.values, var, grad.indices,\n",
    "            lambda x, i, v: standard_ops.scatter_add(x, i, v))\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(FedProxOptimizer, self).get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            \"lr\": self._serialize_hyperparameter(\"learning_rate\"),\n",
    "            \"mu\": self._serialize_hyperparameter(\"mu\")\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(feature_shape, classes):\n",
    "    model = Sequential([\n",
    "        Dense(64, input_shape=feature_shape, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=FedProxOptimizer(mu=1e-1),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a federated model using the build model function and dataset\n",
    "fl_model = FederatedModel(build_model, data_loader=fl_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `FederatedModel` object is a wrapper around your Keras, Tensorflow or PyTorch model that makes it compatible with openfl. It provides built in federated training and validation functions that we will see used below. Using it's `setup` function, collaborator models and datasets can be automatically defined for the experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collaborator_models = fl_model.setup(num_collaborators=10)\n",
    "collaborators = {f'col{col}':collaborator_models[col] for col in range(len(collaborator_models))}#, 'three':collaborator_models[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original MNIST dataset\n",
    "print(f'Original training data size: {len(train_images)}')\n",
    "print(f'Original validation data size: {len(valid_images)}\\n')\n",
    "\n",
    "#Collaborator one's data\n",
    "print(f'Collaborator one\\'s training data size: {len(collaborator_models[0].data_loader.X_train)}')\n",
    "print(f'Collaborator one\\'s validation data size: {len(collaborator_models[0].data_loader.X_valid)}\\n')\n",
    "\n",
    "#Collaborator two's data\n",
    "print(f'Collaborator two\\'s training data size: {len(collaborator_models[1].data_loader.X_train)}')\n",
    "print(f'Collaborator two\\'s validation data size: {len(collaborator_models[1].data_loader.X_valid)}\\n')\n",
    "\n",
    "#Collaborator three's data\n",
    "#print(f'Collaborator three\\'s training data size: {len(collaborator_models[2].data_loader.X_train)}')\n",
    "#print(f'Collaborator three\\'s validation data size: {len(collaborator_models[2].data_loader.X_valid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the current plan values by running the `fx.get_plan()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the current values of the plan. Each of these can be overridden\n",
    "import json\n",
    "print(json.dumps(fx.get_plan(), indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to run our experiment. If we want to pass in custom plan settings, we can easily do that with the `override_config` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Run experiment, return trained FederatedModel\n",
    "final_fl_model = fx.run_experiment(collaborators,override_config={'aggregator.settings.rounds_to_train':5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save final model and load into keras\n",
    "final_fl_model.save_native('final_model')\n",
    "model = tf.keras.models.load_model('./final_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the final model on our test set\n",
    "model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fedprox_keras_mnist_9=[\n",
    "    0.07246376574039459,\n",
    "0.02415458858013153,\n",
    "0.08060453087091446,\n",
    "0.07828282564878464,\n",
    "0.08010470867156982,\n",
    "0.005873139947652817,\n",
    "0.09040793776512146,\n",
    "0.015303430147469044,\n",
    "0.07728459686040878,\n",
    "0.059869591146707535,\n",
    "0.0805152952671051,\n",
    "0.25764894485473633,\n",
    "0.21284635365009308,\n",
    "0.4530302882194519,\n",
    "0.6570680737495422,\n",
    "0.222004696726799,\n",
    "0.26405733823776245,\n",
    "0.05540896952152252,\n",
    "0.44490861892700195,\n",
    "0.18020154535770416,\n",
    "0.15780998766422272,\n",
    "0.4444444477558136,\n",
    "0.509655773639679,\n",
    "0.6025252342224121,\n",
    "0.7282722592353821,\n",
    "0.26037588715553284,\n",
    "0.4994487464427948,\n",
    "0.22744064033031464,\n",
    "0.6214098930358887,\n",
    "0.29934796690940857,\n",
    "0.2415459007024765,\n",
    "0.5813204646110535,\n",
    "0.7065491080284119,\n",
    "0.6823232173919678,\n",
    "0.7837696075439453,\n",
    "0.3132341504096985,\n",
    "0.6730981469154358,\n",
    "0.4849604368209839,\n",
    "0.7503916621208191,\n",
    "0.3698873817920685,\n",
    "0.3035426735877991,\n",
    "0.6103059649467468,\n",
    "0.772879958152771,\n",
    "0.7161616086959839,\n",
    "0.8544502854347229,\n",
    "0.3535630404949188,\n",
    "0.766262412071228,\n",
    "0.5783641338348389,\n",
    "0.8161879777908325,\n",
    "0.3977474868297577,\n",
    "]\n",
    "fedprox_keras_mnist_5 = [0.07246376574039459,\n",
    "0.02415458858013153,\n",
    "0.08060453087091446,\n",
    "0.07828282564878464,\n",
    "0.08010470867156982,\n",
    "0.005873139947652817,\n",
    "0.09040793776512146,\n",
    "0.015303430147469044,\n",
    "0.07728459686040878,\n",
    "0.059869591146707535,\n",
    "0.0805152952671051,\n",
    "0.25764894485473633,\n",
    "0.21200671792030334,\n",
    "0.4530302882194519,\n",
    "0.6560209393501282,\n",
    "0.222004696726799,\n",
    "0.26405733823776245,\n",
    "0.05540896952152252,\n",
    "0.44438642263412476,\n",
    "0.18020154535770416,\n",
    "0.15780998766422272,\n",
    "0.4444444477558136,\n",
    "0.5092359185218811,\n",
    "0.6015151739120483,\n",
    "0.7282722592353821,\n",
    "0.2607674300670624,\n",
    "0.4972436726093292,\n",
    "0.22849604487419128,\n",
    "0.6214098930358887,\n",
    "0.2987551987171173,\n",
    "0.24315619468688965,\n",
    "0.5813204646110535,\n",
    "0.7078085541725159,\n",
    "0.6828283071517944,\n",
    "0.7842931747436523,\n",
    "0.3132341504096985,\n",
    "0.6736493706703186,\n",
    "0.4875989556312561,\n",
    "0.7519582509994507,\n",
    "0.3698873817920685,\n",
    "0.3027375340461731,\n",
    "0.6103059649467468,\n",
    "0.7737195491790771,\n",
    "0.715656578540802,\n",
    "0.8554973602294922,\n",
    "0.35277995467185974,\n",
    "0.7668136954307556,\n",
    "0.5778363943099976,\n",
    "0.8177545666694641,\n",
    "0.39715471863746643,\n",
    "]\n",
    "fedprox_keras_mnist_0 = [0.07246376574039459,\n",
    "0.02415458858013153,\n",
    "0.08060453087091446,\n",
    "0.07828282564878464,\n",
    "0.08010470867156982,\n",
    "0.005873139947652817,\n",
    "0.09040793776512146,\n",
    "0.015303430147469044,\n",
    "0.07728459686040878,\n",
    "0.059869591146707535,\n",
    "0.0805152952671051,\n",
    "0.25764894485473633,\n",
    "0.21200671792030334,\n",
    "0.4530302882194519,\n",
    "0.6565445065498352,\n",
    "0.222004696726799,\n",
    "0.26405733823776245,\n",
    "0.05540896952152252,\n",
    "0.44438642263412476,\n",
    "0.18020154535770416,\n",
    "0.15780998766422272,\n",
    "0.44605475664138794,\n",
    "0.510075569152832,\n",
    "0.6020202040672302,\n",
    "0.727748692035675,\n",
    "0.2607674300670624,\n",
    "0.498346209526062,\n",
    "0.23007915914058685,\n",
    "0.6214098930358887,\n",
    "0.2987551987171173,\n",
    "0.24235104024410248,\n",
    "0.5813204646110535,\n",
    "0.7057095170021057,\n",
    "0.6823232173919678,\n",
    "0.7842931747436523,\n",
    "0.31284260749816895,\n",
    "0.6719955801963806,\n",
    "0.48601582646369934,\n",
    "0.7503916621208191,\n",
    "0.3692946135997772,\n",
    "0.3027375340461731,\n",
    "0.6119162440299988,\n",
    "0.7749789953231812,\n",
    "0.7161616086959839,\n",
    "0.8554973602294922,\n",
    "0.3531714975833893,\n",
    "0.766262412071228,\n",
    "0.577308714389801,\n",
    "0.8177545666694641,\n",
    "0.3977474868297577,]\n",
    "fedprox_keras_mnist_2 = [\n",
    "    0.07246376574039459,\n",
    "0.02415458858013153,\n",
    "0.08060453087091446,\n",
    "0.07828282564878464,\n",
    "0.08010470867156982,\n",
    "0.005873139947652817,\n",
    "0.09040793776512146,\n",
    "0.015303430147469044,\n",
    "0.07728459686040878,\n",
    "0.059869591146707535,\n",
    "0.07729468494653702,\n",
    "0.25764894485473633,\n",
    "0.2086481899023056,\n",
    "0.4515151381492615,\n",
    "0.6575916409492493,\n",
    "0.222004696726799,\n",
    "0.2596471905708313,\n",
    "0.0548812672495842,\n",
    "0.44281983375549316,\n",
    "0.18079431354999542,\n",
    "0.15458936989307404,\n",
    "0.4412238299846649,\n",
    "0.49958017468452454,\n",
    "0.5944444537162781,\n",
    "0.7230366468429565,\n",
    "0.2599843442440033,\n",
    "0.4807056188583374,\n",
    "0.22005276381969452,\n",
    "0.6146214008331299,\n",
    "0.29401305317878723,\n",
    "0.23268921673297882,\n",
    "0.5748792290687561,\n",
    "0.6952140927314758,\n",
    "0.6752524971961975,\n",
    "0.7790575623512268,\n",
    "0.31205952167510986,\n",
    "0.652701199054718,\n",
    "0.4765171408653259,\n",
    "0.7342036366462708,\n",
    "0.3580320179462433,\n",
    "0.2946859896183014,\n",
    "0.6054750680923462,\n",
    "0.7611250877380371,\n",
    "0.7085858583450317,\n",
    "0.8476439714431763,\n",
    "0.3484729826450348,\n",
    "0.7519294619560242,\n",
    "0.5604221820831299,\n",
    "0.8052219152450562,\n",
    "0.3900415003299713,\n",
    "]\n",
    "fedprox_keras_mnist_1 = [\n",
    "    0.07246376574039459,\n",
    "0.02415458858013153,\n",
    "0.08060453087091446,\n",
    "0.07828282564878464,\n",
    "0.08010470867156982,\n",
    "0.005873139947652817,\n",
    "0.09040793776512146,\n",
    "0.015303430147469044,\n",
    "0.07728459686040878,\n",
    "0.059869591146707535,\n",
    "0.06763284653425217,\n",
    "0.249597430229187,\n",
    "0.17800167202949524,\n",
    "0.43282827734947205,\n",
    "0.6612565517425537,\n",
    "0.222004696726799,\n",
    "0.21885336935520172,\n",
    "0.0480211079120636,\n",
    "0.4281984269618988,\n",
    "0.17427386343479156,\n",
    "0.10225442796945572,\n",
    "0.34621578454971313,\n",
    "0.3467674255371094,\n",
    "0.5272727012634277,\n",
    "0.6958115100860596,\n",
    "0.23688332736492157,\n",
    "0.3450937271118164,\n",
    "0.10395778715610504,\n",
    "0.5039164423942566,\n",
    "0.22762300074100494,\n",
    "0.14895330369472504,\n",
    "0.483091801404953,\n",
    "0.507556676864624,\n",
    "0.5747475028038025,\n",
    "0.7036648988723755,\n",
    "0.2760375738143921,\n",
    "0.42833516001701355,\n",
    "0.29445910453796387,\n",
    "0.550391674041748,\n",
    "0.2708950936794281,\n",
    "0.15056361258029938,\n",
    "0.4911433160305023,\n",
    "0.5457598567008972,\n",
    "0.5974747538566589,\n",
    "0.7125654220581055,\n",
    "0.27760374546051025,\n",
    "0.47629547119140625,\n",
    "0.26596304774284363,\n",
    "0.580156683921814,\n",
    "0.2898636758327484,\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(9,6), dpi=150)\n",
    "plt.title('Keras MNIST unbalanced split')\n",
    "plt.plot([np.mean(round_acc) for round_acc in np.array_split(fedprox_keras_mnist_0, 5)], linestyle='--', label='FedAvg')\n",
    "plt.plot([np.mean(round_acc) for round_acc in np.array_split(fedprox_keras_mnist_9, 5)], label='FedProx (mu=1e-9)')\n",
    "plt.plot([np.mean(round_acc) for round_acc in np.array_split(fedprox_keras_mnist_5, 5)], label='FedProx (mu=1e-5)')\n",
    "plt.plot([np.mean(round_acc) for round_acc in np.array_split(fedprox_keras_mnist_2, 5)], label='FedProx (mu=1e-2)')\n",
    "plt.plot([np.mean(round_acc) for round_acc in np.array_split(fedprox_keras_mnist_1, 5)], label='FedProx (mu=1e-1)')\n",
    "\n",
    "plt.legend()\n",
    "plt.xticks(range(5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
